\relax 
\catcode `"\active 
\select@language{slovene}
\@writefile{toc}{\select@language{slovene}}
\@writefile{lof}{\select@language{slovene}}
\@writefile{lot}{\select@language{slovene}}
\@writefile{toc}{\contentsline {chapter}{Kazalo tabel}{vi}}
\citation{IntroductionToPsychology}
\citation{ReinforcementLearningAnIntroduction}
\@writefile{toc}{\contentsline {chapter}{Kazalo slik}{vii}}
\@writefile{brf}{\backcite{IntroductionToPsychology}{{vii}{(document)}{Doc-Start}}}
\@writefile{brf}{\backcite{ReinforcementLearningAnIntroduction}{{vii}{(document)}{Doc-Start}}}
\gdef \LT@i {\LT@entry 
    {1}{28.45274pt}\LT@entry 
    {1}{412.56499pt}}
\@writefile{toc}{\contentsline {chapter}{Seznam kratic}{viii}}
\citation{ACollectionOfDefinitionsOfIntelligence}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Uvod}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{brf}{\backcite{ACollectionOfDefinitionsOfIntelligence}{{1}{1}{}}}
\citation{TDANNForStrategicControlProblems}
\citation{AMathematicalTheoryOfCommunication}
\citation{SomeStudiesInMachineLearningUsingTheGameOfCheckers}
\citation{LearningToPredictByTheMethodsOfTemporalDifference}
\citation{PracticalIssuesInTemporalDifferenceLearning}
\citation{PlayingRiskAversiveGoOnALargeBoardUsingLocalNeuralNetworkPositionEvaluationFunctions}
\citation{StrategyAcquisitionForTheGameOthelloBasedOnReinforcementLearning}
\citation{LearningToEvaluateGoPositionsViaTemporalDifferenceMethods}
\citation{ReinforcementLearningAnIntroduction}
\@writefile{brf}{\backcite{TDANNForStrategicControlProblems}{{2}{1}{}}}
\@writefile{brf}{\backcite{AMathematicalTheoryOfCommunication}{{2}{1}{}}}
\@writefile{brf}{\backcite{SomeStudiesInMachineLearningUsingTheGameOfCheckers}{{2}{1}{}}}
\@writefile{brf}{\backcite{LearningToPredictByTheMethodsOfTemporalDifference}{{2}{1}{}}}
\@writefile{brf}{\backcite{PracticalIssuesInTemporalDifferenceLearning}{{2}{1}{}}}
\@writefile{brf}{\backcite{PlayingRiskAversiveGoOnALargeBoardUsingLocalNeuralNetworkPositionEvaluationFunctions, StrategyAcquisitionForTheGameOthelloBasedOnReinforcementLearning, LearningToEvaluateGoPositionsViaTemporalDifferenceMethods}{{2}{1}{}}}
\@writefile{brf}{\backcite{ReinforcementLearningAnIntroduction}{{2}{1}{}}}
\citation{ConditionedReflexes}
\citation{PavlovianConditioningItsNotWhatYouThinkItIs}
\citation{LearningAndBehaviorAContemporarySynthesis}
\citation{CognitionEvolutionAndBehavior}
\citation{PsychologyAStudentFriendlyApproach}
\citation{IntroductionToPsychology}
\citation{ComputationalModelsOfClassicalConditioningAComparativeStudy}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Psihologija}{3}}
\newlabel{section:Psychology}{{1.1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Klasi\IeC {\v c}no pogojevanje}{3}}
\@writefile{brf}{\backcite{ConditionedReflexes}{{3}{1.1.1}{}}}
\@writefile{brf}{\backcite{PavlovianConditioningItsNotWhatYouThinkItIs, LearningAndBehaviorAContemporarySynthesis, CognitionEvolutionAndBehavior}{{3}{1.1.1}{}}}
\@writefile{brf}{\backcite{PsychologyAStudentFriendlyApproach}{{3}{1.1.1}{}}}
\citation{ReinforcementLearningAnIntroduction}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Klasi\IeC {\v c}no pogojevanje pi\IeC {\v s}\IeC {\v c}alke namesto hrane za slinjenje pri psu~\cite  {IntroductionToPsychology}.}}{4}}
\@writefile{brf}{\backcite{IntroductionToPsychology}{{4}{1.1}{}}}
\newlabel{figure:WhistleAndDog}{{1.1}{4}}
\@writefile{brf}{\backcite{ComputationalModelsOfClassicalConditioningAComparativeStudy}{{4}{1.1.1}{}}}
\@writefile{brf}{\backcite{ReinforcementLearningAnIntroduction}{{4}{1.1.1}{}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Operantno pogojevanje}{4}}
\citation{AnimalIntelligence1}
\citation{AnimalIntelligence2}
\citation{IntroductionToPsychology}
\citation{IntroductionToPsychology}
\citation{IntroductionToPsychology}
\@writefile{brf}{\backcite{AnimalIntelligence1}{{5}{1.1.2}{}}}
\@writefile{brf}{\backcite{AnimalIntelligence2}{{5}{1.1.2}{}}}
\@writefile{brf}{\backcite{IntroductionToPsychology}{{5}{1.1.2}{}}}
\@writefile{brf}{\backcite{IntroductionToPsychology}{{5}{1.1.2}{}}}
\citation{IntroductionToPsychology}
\citation{IntroductionToPsychology}
\@writefile{brf}{\backcite{IntroductionToPsychology}{{6}{1.1.2}{}}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Vpliv pozitivne in negativne okrepitve in kaznovanja na vedenje.}}{6}}
\newlabel{table:OperantConditioningTerms}{{1.1}{6}}
\@writefile{brf}{\backcite{IntroductionToPsychology}{{6}{1.1.2}{}}}
\citation{IntroductionToPsychology}
\citation{MusicDiscriminationByPigeons}
\citation{PigeonsDiscriminationOfPaintings}
\@writefile{brf}{\backcite{IntroductionToPsychology}{{7}{1.1.2}{}}}
\@writefile{brf}{\backcite{IntroductionToPsychology}{{7}{1.1.2}{}}}
\@writefile{brf}{\backcite{MusicDiscriminationByPigeons}{{7}{1.1.2}{}}}
\@writefile{brf}{\backcite{PigeonsDiscriminationOfPaintings}{{7}{1.1.2}{}}}
\citation{ReinforcementLearningAnIntroduction}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Problem okrepitvenega u\IeC {\v c}enja}{8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:Problem}{{2}{8}}
\@writefile{brf}{\backcite{ReinforcementLearningAnIntroduction}{{8}{2}{}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Elementi okrepitvenega u\IeC {\v c}enja}{8}}
\newlabel{section:ReinforcementLearningElements}{{2.1}{8}}
\citation{ReinforcementLearningAnIntroduction}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Interakcija med u\IeC {\v c}encem in njegovim okoljem~\cite  {ReinforcementLearningAnIntroduction}.}}{9}}
\@writefile{brf}{\backcite{ReinforcementLearningAnIntroduction}{{9}{2.1}{}}}
\newlabel{figure:AgentEnvironment}{{2.1}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Kon\IeC {\v c}ni Markov proces odlo\IeC {\v c}anja}{11}}
\newlabel{equation:GeneralCompleteProbabilityDistribution}{{2.1}{11}}
\newlabel{equation:MarkovCompleteProbabilityDistribution}{{2.2}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Diskretno okrepitveno u\IeC {\v c}enje}{12}}
\citation{TheRoleOfExplorationInLearningControl}
\citation{ReinforcementLearningAnIntroduction}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Raziskovanje in izkori\IeC {\v s}\IeC {\v c}anje}{13}}
\@writefile{brf}{\backcite{TheRoleOfExplorationInLearningControl}{{14}{2.4}{}}}
\@writefile{brf}{\backcite{ReinforcementLearningAnIntroduction}{{14}{2.4}{}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}$\epsilon $-po\IeC {\v z}re\IeC {\v s}na izbira dejanj}{14}}
\citation{OnTheTheoryOfDynamicProgramming}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Tabularne re\IeC {\v s}itve}{15}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dinami\IeC {\v c}no programiranje}{15}}
\@writefile{brf}{\backcite{OnTheTheoryOfDynamicProgramming}{{15}{3.1}{}}}
\newlabel{equation:Bellman}{{3.1}{15}}
\citation{ReinforcementLearningWithReplacingEligibilityTraces}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Monte Carlo metode}{16}}
\@writefile{brf}{\backcite{ReinforcementLearningWithReplacingEligibilityTraces}{{16}{3.2}{}}}
\newlabel{equation:RunningAverage}{{3.3}{17}}
\citation{IntroductionToMonteCarloMethods}
\citation{ReinforcementLearningAnIntroduction}
\citation{LearningWithoutStateEstimationInPartiallyObservableMarkovianDecisionProcesses}
\@writefile{brf}{\backcite{IntroductionToMonteCarloMethods}{{18}{3.2}{}}}
\@writefile{brf}{\backcite{ReinforcementLearningAnIntroduction}{{18}{3.2}{}}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}U\IeC {\v c}enje na podlagi \IeC {\v c}asovne razlike - TD(0)}{18}}
\newlabel{subsection:TD0Prediction}{{3.3}{18}}
\@writefile{brf}{\backcite{LearningWithoutStateEstimationInPartiallyObservableMarkovianDecisionProcesses}{{18}{3.3}{}}}
\citation{ReinforcementLearningWithReplacingEligibilityTraces}
\citation{ReinforcementLearningAnIntroduction}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Zdru\IeC {\v z}itev metod - TD($\lambda $)}{19}}
\citation{LearningWithoutStateEstimationInPartiallyObservableMarkovianDecisionProcesses}
\@writefile{brf}{\backcite{ReinforcementLearningWithReplacingEligibilityTraces}{{20}{3.4}{}}}
\@writefile{brf}{\backcite{ReinforcementLearningAnIntroduction}{{20}{3.4}{}}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Algoritem TD($\lambda $) z zamenjavnimi sledmi.}}{20}}
\newlabel{table:TDLambda}{{3.1}{20}}
\@writefile{brf}{\backcite{LearningWithoutStateEstimationInPartiallyObservableMarkovianDecisionProcesses}{{21}{3.4}{}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Posplo\IeC {\v s}evanje in funkcijska aproksimacija}{22}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Nevronske mre\IeC {\v z}e}{22}}
\citation{UnderstandingTheDifficultyOfTrainingDeepFeedforwardNeuralNetworks}
\citation{Perceptrons}
\citation{MultilayerFeedforwardNetworksAreUniversalApproximators}
\citation{TDANNForStrategicControlProblems}
\@writefile{brf}{\backcite{UnderstandingTheDifficultyOfTrainingDeepFeedforwardNeuralNetworks}{{23}{4.1}{}}}
\@writefile{brf}{\backcite{Perceptrons}{{23}{4.1}{}}}
\@writefile{brf}{\backcite{MultilayerFeedforwardNetworksAreUniversalApproximators}{{23}{4.1}{}}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Zdru\IeC {\v z}itev TD($\lambda $) z nevronskimi mre\IeC {\v z}ami}{23}}
\@writefile{brf}{\backcite{TDANNForStrategicControlProblems}{{23}{4.2}{}}}
\citation{AnAnalysisOfTemporalDifferenceLearningWithFunctionApproximation}
\citation{GeneralizationInReinforcementLearningSafelyApproximatingTheValueFunction}
\citation{PracticalIssuesInTemporalDifferenceLearning}
\@writefile{brf}{\backcite{AnAnalysisOfTemporalDifferenceLearningWithFunctionApproximation}{{24}{4.2}{}}}
\@writefile{brf}{\backcite{GeneralizationInReinforcementLearningSafelyApproximatingTheValueFunction}{{24}{4.2}{}}}
\@writefile{brf}{\backcite{PracticalIssuesInTemporalDifferenceLearning}{{24}{4.2}{}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}U\IeC {\v c}enje na namizni igri Hex}{25}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Ozadje}{25}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Implementacija}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}U\IeC {\v c}enec tabularne TD($\lambda )$}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}U\IeC {\v c}enec TD($\lambda $) z nevronsko mre\IeC {\v z}o}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Naklju\IeC {\v c}ni igralec}{25}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Rezultati}{25}}
\citation{ReinforcementLearningAnIntroduction}
\citation{TheSingularityIsNear}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Zaklju\IeC {\v c}ek}{26}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{brf}{\backcite{ReinforcementLearningAnIntroduction}{{26}{6}{}}}
\@writefile{brf}{\backcite{TheSingularityIsNear}{{26}{6}{}}}
\bibcite{SomeStudiesInMachineLearningUsingTheGameOfCheckers}{1}
\bibcite{TDANNForStrategicControlProblems}{2}
\bibcite{ComputationalModelsOfClassicalConditioningAComparativeStudy}{3}
\bibcite{AMathematicalTheoryOfCommunication}{4}
\bibcite{IntroductionToPsychology}{5}
\bibcite{IntroductionToMonteCarloMethods}{6}
\bibcite{MusicDiscriminationByPigeons}{7}
\bibcite{AnimalIntelligence1}{8}
\bibcite{AnimalIntelligence2}{9}
\bibcite{PlayingRiskAversiveGoOnALargeBoardUsingLocalNeuralNetworkPositionEvaluationFunctions}{10}
\bibcite{PracticalIssuesInTemporalDifferenceLearning}{11}
\@writefile{toc}{\contentsline {chapter}{Literatura}{28}}
\bibcite{ConditionedReflexes}{12}
\bibcite{GeneralizationInReinforcementLearningSafelyApproximatingTheValueFunction}{13}
\bibcite{AnAnalysisOfTemporalDifferenceLearningWithFunctionApproximation}{14}
\bibcite{MultilayerFeedforwardNetworksAreUniversalApproximators}{15}
\bibcite{ALearningRuleForVerySimpleUniversalApproximatorsConsistingOfASingleLayerOfPerceptrons}{16}
\bibcite{PavlovianConditioningItsNotWhatYouThinkItIs}{17}
\bibcite{OnTheTheoryOfDynamicProgramming}{18}
\bibcite{TheSingularityIsNear}{19}
\bibcite{LearningToPredictByTheMethodsOfTemporalDifference}{20}
\bibcite{ReinforcementLearningAnIntroduction}{21}
\bibcite{LearningAndBehaviorAContemporarySynthesis}{22}
\bibcite{StrategyAcquisitionForTheGameOthelloBasedOnReinforcementLearning}{23}
\bibcite{Perceptrons}{24}
\bibcite{LearningToEvaluateGoPositionsViaTemporalDifferenceMethods}{25}
\bibcite{TheRoleOfExplorationInLearningControl}{26}
\bibcite{CognitionEvolutionAndBehavior}{27}
\bibcite{ACollectionOfDefinitionsOfIntelligence}{28}
\bibcite{ReinforcementLearningWithReplacingEligibilityTraces}{29}
\bibcite{LearningWithoutStateEstimationInPartiallyObservableMarkovianDecisionProcesses}{30}
\bibcite{PigeonsDiscriminationOfPaintings}{31}
\bibcite{PsychologyAStudentFriendlyApproach}{32}
\bibcite{PlayingAtariWithDeepReinforcementLearning}{33}
\bibcite{UnderstandingTheDifficultyOfTrainingDeepFeedforwardNeuralNetworks}{34}
